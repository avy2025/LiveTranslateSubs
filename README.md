![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Flask](https://img.shields.io/badge/Flask-Web_Framework-green)
![Whisper](https://img.shields.io/badge/Whisper-GenAI-orange)
![Socket.IO](https://img.shields.io/badge/Socket.IO-Realtime-black)
![Status](https://img.shields.io/badge/Status-Working-success)

# ğŸ¤ LiveTranslateSubs â€” Real-Time Speech Translation

LiveTranslateSubs is a **real-time speech-to-text and translation web application** built using **Flask, Socket.IO, and OpenAI Whisper (faster-whisper)**.  
It captures microphone audio from the browser, transcribes spoken language, and translates it into English with **low latency**.

This project demonstrates practical usage of **GenAI, audio processing, WebSockets, and full-stack development**.

---

## ğŸš€ Features

- ğŸ™ï¸ Live microphone audio recording from browser  
- ğŸ§  Speech recognition using **Whisper (faster-whisper)**  
- ğŸŒ Automatic language detection & translation  
- âš¡ Real-time communication via **Socket.IO**  
- ğŸ”Š Voice Activity Detection (VAD) for better accuracy  
- ğŸ’» Optimized for **CPU execution** (no GPU required)

---

## ğŸ› ï¸ Tech Stack

**Frontend**
- HTML, CSS, JavaScript
- MediaRecorder API
- Socket.IO Client

**Backend**
- Python
- Flask
- Flask-SocketIO
- faster-whisper
- FFmpeg
- NumPy

---
## ğŸ§  How It Works

1. Browser records microphone audio using MediaRecorder API
2. Audio is sent to the backend via Socket.IO
3. FFmpeg converts WebM/Opus audio to PCM float32
4. Whisper model performs speech recognition
5. Detected speech is translated into English
6. Transcribed subtitles are sent back to the browser in real time
---
## ğŸ“ Project Structure

LiveTranslationCaption/
â”‚
â”œâ”€â”€ app.py # Main Flask + Socket.IO server
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ requirements.txt # Python dependencies

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/LiveTranslateSubs.git
cd LiveTranslateSubs

2ï¸âƒ£ Install Python dependencies
pip install flask flask-socketio faster-whisper ffmpeg-python numpy

3ï¸âƒ£ Install FFmpeg (Required)

Download from: https://www.gyan.dev/ffmpeg/builds/

Extract and note the bin path

Example:

C:\Users\admin\Downloads\ffmpeg\bin


FFmpeg is required for decoding audio.
â–¶ï¸ Run the Application
python app.py


Open your browser and visit:

http://127.0.0.1:5000


Click Record, speak clearly, and see live translated subtitles

ğŸ“Œ Key Learnings

Real-time audio streaming using WebSockets

Audio format conversion (WebM â†’ PCM)

Integrating GenAI models in web applications

Handling browser microphone APIs

Building production-ready Flask applications

ğŸ”® Future Improvements

True real-time streaming (chunk-based transcription)

Support for original + translated subtitles

Improved accuracy using larger Whisper models

Deployment on cloud (Render / Railway)

Mobile-friendly UI

ğŸ¤ Contributing

Contributions are welcome!
Feel free to fork this repo, raise issues, or submit pull requests.

ğŸ“œ License

This project is licensed under the MIT License.

ğŸ‘¨â€ğŸ’» Author

Ranjan Thakur
